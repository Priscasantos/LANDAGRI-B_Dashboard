# -*- coding: utf-8 -*-
"""
Gerador de Dados das Iniciativas LULC
=====================================

Este script cria o dataset principal em formato CSV com todas as caracterÃ­sticas
das iniciativas de mapeamento de cobertura e uso da terra (LULC).

Autor: AnÃ¡lise Comparativa de Iniciativas LULC
Data: 2024
"""

import pandas as pd
import numpy as np

def create_initiatives_dataset():
    """
    Cria o dataset principal com dados de todas as iniciativas LULC.
    
    Returns:
        pd.DataFrame: DataFrame com dados das iniciativas
    """
    
    # Dados das 14 principais iniciativas LULC
    initiatives_data = {
        'Nome': [
            'Copernicus Global Land Cover Service (CGLS)',
            'Dynamic World (GDW)',
            'ESRI-10m Annual LULC',
            'FROM-GLC',
            'WorldCover 10m 2021',
            'Land Cover CCI',
            'MODIS Land Cover',
            'GLC_FCS30',
            'MapBiomas Brasil',
            'PRODES AmazÃ´nia',
            'DETER AmazÃ´nia',
            'PRODES Cerrado',
            'TerraClass AmazÃ´nia',
            'IBGE Monitoramento'
        ],
        'Tipo': [
            'Global', 'Global', 'Global', 'Global', 'Global', 'Global', 'Global', 'Global',
            'Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional', 'Nacional'
        ],
        'ResoluÃ§Ã£o (m)': [
            100, 10, 10, 30, 10, 300, 500, 30, 30, 30, 250, 30, 30, 30
        ],
        'AcurÃ¡cia (%)': [
            75, 74, 76, 71, 77, 73, 67, 68, 89, 95, 85, 92, 88, 85
        ],
        'Classes': [
            23, 9, 10, 10, 11, 37, 17, 29, 27, 2, 2, 2, 12, 15
        ],
        'Metodologia': [
            'Machine Learning', 'Deep Learning', 'Deep Learning', 'Random Forest', 
            'Machine Learning', 'ClassificaÃ§Ã£o Supervisionada', 'Decision Trees', 
            'Random Forest', 'Random Forest', 'InterpretaÃ§Ã£o Visual', 
            'DetecÃ§Ã£o AutomÃ¡tica', 'InterpretaÃ§Ã£o Visual', 'ClassificaÃ§Ã£o Supervisionada',
            'InterpretaÃ§Ã£o Manual'
        ],
        'FrequÃªncia Temporal': [
            'Anual', 'Tempo Real', 'Anual', 'Multi-temporal', 'Anual', 'Anual', 'Anual',
            'Pontual', 'Anual', 'Anual', 'Tempo Real', 'Bienal', 'Bienal', 'Bienal'
        ],
        'Anos DisponÃ­veis': [
            '2015-2023', '2015-2024', '2017-2023', '2010-2017', '2021', '1992-2020',
            '2001-2023', '2020', '1985-2023', '1988-2023', '2004-2024', '2000-2022',
            '2008-2020', '2000-2022'
        ],
        'Escopo': [
            'Global', 'Global', 'Global', 'Global', 'Global', 'Global', 'Global', 'Global',
            'Brasil', 'AmazÃ´nia Legal', 'AmazÃ´nia Legal', 'Cerrado', 'AmazÃ´nia Legal', 'Brasil'
        ]
    }
    
    # Criar DataFrame
    df = pd.DataFrame(initiatives_data)
    
    return df

def add_derived_metrics(df):
    """
    Adiciona mÃ©tricas derivadas ao dataset.
    
    Args:
        df (pd.DataFrame): DataFrame original
        
    Returns:
        pd.DataFrame: DataFrame com mÃ©tricas adicionais
    """
    
    # Calcular score de resoluÃ§Ã£o (menor resoluÃ§Ã£o = melhor score)
    df['Score ResoluÃ§Ã£o'] = 1000 / df['ResoluÃ§Ã£o (m)']
    
    # Calcular score geral (combinaÃ§Ã£o de acurÃ¡cia e resoluÃ§Ã£o)
    df['Score Geral'] = (df['AcurÃ¡cia (%)'] * 0.7) + (df['Score ResoluÃ§Ã£o'] * 0.3)
    
    # Categorizar por faixa de acurÃ¡cia
    def categorize_accuracy(accuracy):
        if accuracy >= 90:
            return 'Muito Alta'
        elif accuracy >= 80:
            return 'Alta'
        elif accuracy >= 70:
            return 'MÃ©dia'
        else:
            return 'Baixa'
    
    df['Categoria AcurÃ¡cia'] = df['AcurÃ¡cia (%)'].apply(categorize_accuracy)
    
    # Categorizar por resoluÃ§Ã£o
    def categorize_resolution(resolution):
        if resolution <= 10:
            return 'Muito Alta'
        elif resolution <= 30:
            return 'Alta'
        elif resolution <= 100:
            return 'MÃ©dia'
        else:
            return 'Baixa'
    
    df['Categoria ResoluÃ§Ã£o'] = df['ResoluÃ§Ã£o (m)'].apply(categorize_resolution)
    
    return df

def save_dataset_to_csv(df, filename='initiatives_comparison.csv'):
    """
    Salva o dataset em arquivo CSV.
    
    Args:
        df (pd.DataFrame): DataFrame para salvar
        filename (str): Nome do arquivo de saÃ­da
    """
    try:
        df.to_csv(filename, index=False, encoding='utf-8')
        
        print(f"âœ… Arquivo {filename} criado com sucesso!")
        print(f"ğŸ“Š Dataset com {len(df)} iniciativas e {len(df.columns)} colunas")
        
        # EstatÃ­sticas do dataset
        print("\nğŸ“ˆ EstatÃ­sticas do dataset:")
        print(f"   - Iniciativas globais: {len(df[df['Tipo'] == 'Global'])}")
        print(f"   - Iniciativas nacionais: {len(df[df['Tipo'] == 'Nacional'])}")
        print(f"   - AcurÃ¡cia mÃ©dia: {df['AcurÃ¡cia (%)'].mean():.1f}%")
        print(f"   - ResoluÃ§Ã£o mÃ©dia: {df['ResoluÃ§Ã£o (m)'].mean():.0f}m")
        print(f"   - Total de classes: {df['Classes'].sum()}")
        
        # Top 3 por acurÃ¡cia
        print(f"\nğŸ† Top 3 em acurÃ¡cia:")
        top_accuracy = df.nlargest(3, 'AcurÃ¡cia (%)')
        for i, (_, row) in enumerate(top_accuracy.iterrows(), 1):
            print(f"   {i}. {row['Nome']} - {row['AcurÃ¡cia (%)']}%")
        
        # Top 3 por resoluÃ§Ã£o
        print(f"\nğŸ” Top 3 em resoluÃ§Ã£o:")
        top_resolution = df.nsmallest(3, 'ResoluÃ§Ã£o (m)')
        for i, (_, row) in enumerate(top_resolution.iterrows(), 1):
            print(f"   {i}. {row['Nome']} - {row['ResoluÃ§Ã£o (m)']}m")
        
    except Exception as e:
        print(f"âŒ Erro ao salvar arquivo: {e}")

def validate_dataset(df):
    """
    Valida a consistÃªncia do dataset.
    
    Args:
        df (pd.DataFrame): DataFrame para validar
    """
    print("\nğŸ” ValidaÃ§Ã£o do dataset:")
    
    # Verificar valores nulos
    null_counts = df.isnull().sum()
    if null_counts.sum() == 0:
        print("   âœ… Nenhum valor nulo encontrado")
    else:
        print(f"   âš ï¸ Valores nulos encontrados: {null_counts.sum()}")
    
    # Verificar duplicatas
    if df.duplicated().sum() == 0:
        print("   âœ… Nenhuma duplicata encontrada")
    else:
        print(f"   âš ï¸ Duplicatas encontradas: {df.duplicated().sum()}")
    
    # Verificar faixas de valores
    if df['AcurÃ¡cia (%)'].min() >= 0 and df['AcurÃ¡cia (%)'].max() <= 100:
        print("   âœ… AcurÃ¡cia em faixa vÃ¡lida (0-100%)")
    else:
        print("   âš ï¸ AcurÃ¡cia fora da faixa vÃ¡lida")
    
    if df['ResoluÃ§Ã£o (m)'].min() > 0:
        print("   âœ… ResoluÃ§Ã£o com valores positivos")
    else:
        print("   âš ï¸ ResoluÃ§Ã£o com valores invÃ¡lidos")

def main():
    """FunÃ§Ã£o principal para executar a geraÃ§Ã£o do dataset."""
    print("ğŸŒ Gerador de Dataset - Iniciativas LULC")
    print("=" * 50)
    
    # Criar dataset
    print("\nğŸ“Š Criando dataset das iniciativas...")
    df = create_initiatives_dataset()
    
    # Adicionar mÃ©tricas derivadas
    print("ğŸ“ˆ Adicionando mÃ©tricas derivadas...")
    df = add_derived_metrics(df)
    
    # Validar dataset
    validate_dataset(df)
    
    # Salvar em CSV
    print("\nğŸ’¾ Salvando dataset em CSV...")
    save_dataset_to_csv(df)
    
    print("\nâœ¨ Processo concluÃ­do com sucesso!")
    
    return df

if __name__ == "__main__":
    df = main()
