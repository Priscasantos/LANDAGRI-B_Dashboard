# -*- coding: utf-8 -*-
"""
Gerador de Dados das Iniciativas LULC
=====================================

Este script cria o dataset principal em formato CSV com todas as caracterÃ­sticas
das iniciativas de mapeamento de cobertura e uso da terra (LULC).

Autor: AnÃ¡lise Comparativa de Iniciativas LULC
Data: 2024
"""

import pandas as pd
import numpy as np

def create_initiatives_dataset():
    """
    Cria o dataset principal com dados de todas as iniciativas LULC.
    
    Returns:
        pd.DataFrame: DataFrame com dados das iniciativas
    """
      # Dados das principais iniciativas LULC baseadas nas tabelas atualizadas
    initiatives_data = {
        'Nome': [
            'Copernicus Global Land Cover Service (CGLS)',
            'Dynamic World (GDW)',
            'ESRI-10m Annual LULC',
            'FROM-GLC',
            'Global LULC change 2000 and 2020',
            'Global Pasture Watch (GPW)',
            'South America Soybean Maps',
            'WorldCover 10m 2021',
            'WorldCereal',
            'Land Cover CCI',
            'MODIS Land Cover',
            'GLC_FCS30',
            'MapBiomas Brasil',
            'PRODES AmazÃ´nia',
            'DETER AmazÃ´nia', 
            'PRODES Cerrado',
            'TerraClass AmazÃ´nia',
            'IBGE Monitoramento',
            'Agricultural Mapping'
        ],
        'Tipo': [
            'Global', 'Global', 'Global', 'Global', 'Global', 'Global', 'Regional',
            'Global', 'Global', 'Global', 'Global', 'Global',
            'Nacional', 'Regional', 'Regional', 'Regional', 'Regional', 'Nacional', 'Nacional'
        ],
        'ResoluÃ§Ã£o (m)': [
            100, 10, 10, 30, 30, 30, 30, 10, 10, 300, 500, 30, 30, 25, 60, 10, 20, 30, 25
        ],
        'AcurÃ¡cia (%)': [
            80.3, 73.8, 85.0, 71, 85.0, 91.0, 94, 76.7, 97.8, 73, 67, 68, 90.0, 93.0, 93.0, 90.9, 93.9, 0, 0        ],
        'Classes': [
            10, 9, 15, 10, 7, 3, 2, 11, 5, 37, 17, 29, 29, 5, 3, 15, 18, 12, 8
        ],
        'Metodologia': [
            'Supervised Random Forest', 'Deep Learning', 'U-Net Deep Learning', 'Random Forest', 
            'Supervised Machine Learning', 'Supervised Machine Learning', 'Combined Methods', 
            'Gradient Boosting', 'CatBoost Gradient Boosting', 'ClassificaÃ§Ã£o Supervisionada', 'Boosted Decision Trees', 
            'Random Forest', 'Supervised Random Forest and U-Net Deep Learning', 'Visual Interpretation and Linear Spectral Mixture Model', 
            'Linear Spectral Mixture Model', 'Visual Interpretation and Deep Learning', 'Visual Interpretation and Deep Learning',
            'Visual Interpretation', 'Machine Learning and Visual Interpretation'
        ],
        'FrequÃªncia Temporal': [
            'Anual', 'Near real time', 'Annual or Sub-annual', 'Multi-temporal', 'Cada 4 anos', 'Bi-Annual', 'Anual',
            'Anual', 'Annual and seasonal', 'Anual', 'Anual', 'Pontual', 'Anual', 'Anual', 'Annual since 2012', 'Bienal', 'Bienal', 'Biannual since 2010', 'By Crop Year'
        ],
        'Anos DisponÃ­veis': [
            '2015,2016,2017,2018,2019', '2017,2018,2019,2020,2021,2022,2023,2024', '2017,2018,2019,2020,2021,2022,2023,2024', '2010,2015,2017', 
            '2000,2005,2015,2020', '2000,2002,2004,2006,2008,2010,2012,2014,2016,2018,2020,2022', 
            '2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023',
            '2020,2021', '2021', '1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020',
            '2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023', '2020', 
            '1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023',
            '2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023', 
            '2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023', '2018,2020,2022', 
            '2008,2010,2012,2014,2016,2018,2020,2022', '2000,2002,2004,2006,2008,2010,2012,2014,2016,2018,2020', '2018,2019,2020,2021,2022,2023'
        ],
        'Escopo': [
            'Global', 'Global', 'Global', 'Global', 'Global', 'Global', 'Regional (South America)',
            'Global', 'Global', 'Global', 'Global', 'Global',
            'Nacional (Brasil)', 'Regional (AmazÃ´nia)', 'Regional (AmazÃ´nia)', 'Regional (Cerrado)', 'Regional (AmazÃ´nia e Cerrado)', 'Nacional (Brasil)', 'Nacional (Brasil)'
        ],
        'Provedor': [
            'Copernicus European Union\'s Space Program', 'Google and World Resources Institute', 'Environmental Systems Research Institute (ESRI)', 'Tsinghua University',
            'University of Maryland (UMD)', 'Land & Carbon Lab', 'University of Maryland (UMD)', 'European Space Agency (ESA)', 'European Space Agency (ESA)',
            'ESA Climate Change Initiative', 'NASA', 'Chinese Academy of Sciences', 'Non-governmental Organizations', 'National Institute for Space Research (INPE)',
            'National Institute for Space Research (INPE)', 'National Institute for Space Research (INPE)', 'National Institute for Space Research (INPE)', 'Brazilian Institute of Geography and Statistics (IBGE)', 'National Supply Company (Conab)'
        ]
    }
    
    # Criar DataFrame
    df = pd.DataFrame(initiatives_data)
    
    return df

def add_derived_metrics(df):
    """
    Adiciona mÃ©tricas derivadas ao dataset.
    
    Args:
        df (pd.DataFrame): DataFrame original
        
    Returns:
        pd.DataFrame: DataFrame com mÃ©tricas adicionais
    """
    
    # Calcular score de resoluÃ§Ã£o (menor resoluÃ§Ã£o = melhor score)
    df['Score ResoluÃ§Ã£o'] = 1000 / df['ResoluÃ§Ã£o (m)']
    
    # Calcular score geral (combinaÃ§Ã£o de acurÃ¡cia e resoluÃ§Ã£o)
    df['Score Geral'] = (df['AcurÃ¡cia (%)'] * 0.7) + (df['Score ResoluÃ§Ã£o'] * 0.3)
    
    # Categorizar por faixa de acurÃ¡cia
    def categorize_accuracy(accuracy):
        if accuracy >= 90:
            return 'Muito Alta'
        elif accuracy >= 80:
            return 'Alta'
        elif accuracy >= 70:
            return 'MÃ©dia'
        else:
            return 'Baixa'
    
    df['Categoria AcurÃ¡cia'] = df['AcurÃ¡cia (%)'].apply(categorize_accuracy)
    
    # Categorizar por resoluÃ§Ã£o
    def categorize_resolution(resolution):
        if resolution <= 10:
            return 'Muito Alta'
        elif resolution <= 30:
            return 'Alta'
        elif resolution <= 100:
            return 'MÃ©dia'
        else:
            return 'Baixa'
    
    df['Categoria ResoluÃ§Ã£o'] = df['ResoluÃ§Ã£o (m)'].apply(categorize_resolution)
    
    return df

def save_dataset_to_csv(df, filename='initiatives_comparison.csv'):
    """
    Salva o dataset em arquivo CSV.
    
    Args:
        df (pd.DataFrame): DataFrame para salvar
        filename (str): Nome do arquivo de saÃ­da
    """
    try:
        df.to_csv(filename, index=False, encoding='utf-8')
        
        print(f"âœ… Arquivo {filename} criado com sucesso!")
        print(f"ğŸ“Š Dataset com {len(df)} iniciativas e {len(df.columns)} colunas")
        
        # EstatÃ­sticas do dataset
        print("\nğŸ“ˆ EstatÃ­sticas do dataset:")
        print(f"   - Iniciativas globais: {len(df[df['Tipo'] == 'Global'])}")
        print(f"   - Iniciativas nacionais: {len(df[df['Tipo'] == 'Nacional'])}")
        print(f"   - AcurÃ¡cia mÃ©dia: {df['AcurÃ¡cia (%)'].mean():.1f}%")
        print(f"   - ResoluÃ§Ã£o mÃ©dia: {df['ResoluÃ§Ã£o (m)'].mean():.0f}m")
        print(f"   - Total de classes: {df['Classes'].sum()}")
        
        # Top 3 por acurÃ¡cia
        print(f"\nğŸ† Top 3 em acurÃ¡cia:")
        top_accuracy = df.nlargest(3, 'AcurÃ¡cia (%)')
        for i, (_, row) in enumerate(top_accuracy.iterrows(), 1):
            print(f"   {i}. {row['Nome']} - {row['AcurÃ¡cia (%)']}%")
        
        # Top 3 por resoluÃ§Ã£o
        print(f"\nğŸ” Top 3 em resoluÃ§Ã£o:")
        top_resolution = df.nsmallest(3, 'ResoluÃ§Ã£o (m)')
        for i, (_, row) in enumerate(top_resolution.iterrows(), 1):
            print(f"   {i}. {row['Nome']} - {row['ResoluÃ§Ã£o (m)']}m")
        
    except Exception as e:
        print(f"âŒ Erro ao salvar arquivo: {e}")

def validate_dataset(df):
    """
    Valida a consistÃªncia do dataset.
    
    Args:
        df (pd.DataFrame): DataFrame para validar
    """
    print("\nğŸ” ValidaÃ§Ã£o do dataset:")
    
    # Verificar valores nulos
    null_counts = df.isnull().sum()
    if null_counts.sum() == 0:
        print("   âœ… Nenhum valor nulo encontrado")
    else:
        print(f"   âš ï¸ Valores nulos encontrados: {null_counts.sum()}")
    
    # Verificar duplicatas
    if df.duplicated().sum() == 0:
        print("   âœ… Nenhuma duplicata encontrada")
    else:
        print(f"   âš ï¸ Duplicatas encontradas: {df.duplicated().sum()}")
    
    # Verificar faixas de valores
    if df['AcurÃ¡cia (%)'].min() >= 0 and df['AcurÃ¡cia (%)'].max() <= 100:
        print("   âœ… AcurÃ¡cia em faixa vÃ¡lida (0-100%)")
    else:
        print("   âš ï¸ AcurÃ¡cia fora da faixa vÃ¡lida")
    
    if df['ResoluÃ§Ã£o (m)'].min() > 0:
        print("   âœ… ResoluÃ§Ã£o com valores positivos")
    else:
        print("   âš ï¸ ResoluÃ§Ã£o com valores invÃ¡lidos")

def main():
    """FunÃ§Ã£o principal para executar a geraÃ§Ã£o do dataset."""
    print("ğŸŒ Gerador de Dataset - Iniciativas LULC")
    print("=" * 50)
    
    # Criar dataset
    print("\nğŸ“Š Criando dataset das iniciativas...")
    df = create_initiatives_dataset()
    
    # Adicionar mÃ©tricas derivadas
    print("ğŸ“ˆ Adicionando mÃ©tricas derivadas...")
    df = add_derived_metrics(df)
    
    # Validar dataset
    validate_dataset(df)
    
    # Salvar em CSV
    print("\nğŸ’¾ Salvando dataset em CSV...")
    save_dataset_to_csv(df)
    
    print("\nâœ¨ Processo concluÃ­do com sucesso!")
    
    return df

if __name__ == "__main__":
    df = main()
