#!/usr/bin/env python3
"""
Script principal modernizado para an√°lise completa das iniciativas LULC.

Este script executa todos os m√≥dulos de an√°lise na ordem correta:
1. Preview dos dados
2. An√°lise principal com gr√°ficos comparativos 
3. Gr√°ficos temporais 
4. Gr√°ficos detalhados 

Estrutura de sa√≠da:
- graphics/comparisons/  - PNGs dos gr√°ficos comparativos entre iniciativas
- graphics/temporal/     - PNGs das an√°lises temporais das iniciativas  
- graphics/detailed/     - PNGs das an√°lises detalhadas espec√≠ficas

Estrutura do dashboard interativo:
- dashboard/comparisons/ - M√≥dulos Streamlit para an√°lises comparativas
- dashboard/temporal/    - M√≥dulos Streamlit para an√°lises temporais
- dashboard/detailed/    - M√≥dulos Streamlit para an√°lises detalhadas

Baseado na estrutura padr√£o do dashboard-agricultura
Autor: Sistema de An√°lise LULC
Data: 2025
"""

import sys
from pathlib import Path
import pandas as pd # Added import for pd.Series

# Global cache for data loading optimization
_DATA_CACHE = {}

def get_cached_data():
    """Get cached data or load it if not cached"""
    if 'data' not in _DATA_CACHE:
        from scripts.data_generation.data_wrapper import load_data, prepare_plot_data
        df, metadata, _ = load_data()
        df_prepared_dict = prepare_plot_data(df)
        df_for_plots = df_prepared_dict.get('data', pd.DataFrame())
        _DATA_CACHE['data'] = {
            'df': df,
            'metadata': metadata,
            'df_for_plots': df_for_plots
        }
        print(f"üìä Dados carregados e cachados: {len(df_for_plots)} iniciativas")
    return _DATA_CACHE['data']

# Adicionar o diret√≥rio scripts ao path
scripts_dir = Path(__file__).parent / "scripts"
sys.path.append(str(scripts_dir))

def run_analysis_step(module_name, description):
    """Executa um passo da an√°lise e trata erros"""
    print(f"\n{'='*60}")
    print(f"üîÑ EXECUTANDO: {description}")
    print(f"{'='*60}")
    
    try:
        if module_name == "preview_dados":
            from scripts.data_generation.data_wrapper import load_data  # Use correct import
            # Preview dos dados carregados
            print("üìä Carregando dados das iniciativas LULC...")
            df, metadata, _ = load_data()  # Fixed tuple unpacking
            print(f"‚úÖ Dados carregados: {len(df)} iniciativas")
            print(f"üìã Colunas dispon√≠veis: {list(df.columns)}")
            if 'Type' in df.columns:
                print(f"üè∑Ô∏è Tipos de iniciativas: {df['Type'].unique().tolist()}")            
            elif 'Tipo' in df.columns:
                print(f"üè∑Ô∏è Tipos de iniciativas: {df['Tipo'].unique().tolist()}")
                
        elif module_name == "analise_comparativa":
            # Use cached data for better performance
            cached_data = get_cached_data()
            df_for_plots = cached_data['df_for_plots']
            metadata = cached_data['metadata']
            
            # Import direct from modular chart files for better performance
            from scripts.plotting.charts.distribution_charts import (
                plot_resolution_accuracy,
                plot_classes_por_iniciativa,
                plot_distribuicao_classes,
                plot_distribuicao_metodologias
            )
            from scripts.plotting.charts.timeline_chart import plot_timeline
            
            plot_resolution_accuracy(df_for_plots)
            plot_timeline(metadata, df_for_plots) # Added metadata
            plot_classes_por_iniciativa(df_for_plots)
            plot_distribuicao_classes(df_for_plots)
            plot_distribuicao_metodologias(df_for_plots['Methodology'].value_counts() if 'Methodology' in df_for_plots and not df_for_plots.empty else pd.Series())
            
        elif module_name == "analise_temporal":
            from dashboard.temporal.temporal import run_non_streamlit
            from scripts.data_generation.data_wrapper import load_data # Corrected import
            # Load data and pass to temporal analysis
            df, metadata, _ = load_data() # Load processed data
            
            # Execute temporal analysis without Streamlit UI
            success = run_non_streamlit(metadata, df, "graphics/temporal")
            if not success:
                print("‚ùå Falha na gera√ß√£o das an√°lises temporais")
                return False            
        elif module_name == "analise_detalhada":
            from dashboard.detailed.detailed import run_non_streamlit as detailed_run_non_streamlit
            from scripts.data_generation.data_wrapper import load_data # Corrected import
            # Load data and pass to detailed analysis
            df, metadata, _ = load_data() # Load processed data
            
            # Execute detailed analysis without Streamlit UI
            success = detailed_run_non_streamlit(df, metadata, "graphics/detailed")
            if not success:
                print("‚ùå Falha na gera√ß√£o das an√°lises detalhadas")
                return False
        
        print(f"‚úÖ {description} - CONCLU√çDO COM SUCESSO!")
        return True
        
    except ImportError as e:
        print(f"‚ùå ERRO DE IMPORTA√á√ÉO: {e}")
        print("üí° Verifique se todas as depend√™ncias est√£o instaladas:")
        print("   pip install -r requirements.txt")
        return False
        
    except Exception as e:
        print(f"‚ùå ERRO DURANTE EXECU√á√ÉO: {e}")
        print(f"üí° Verifique o m√≥dulo: {module_name}")
        return False

def check_dependencies():
    """Verifica se as depend√™ncias necess√°rias est√£o instaladas"""
    required_packages = ["pandas", "matplotlib", "numpy", "plotly", "seaborn", "streamlit"]
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("‚ùå DEPEND√äNCIAS FALTANDO:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\nüí° Execute primeiro: pip install -r requirements.txt")
        return False
    
    print("‚úÖ Todas as depend√™ncias est√£o instaladas!")
    return True

def create_output_directories():
    """Cria os diret√≥rios de sa√≠da para PNGs se n√£o existirem"""
    directories = [
        "graphics/comparisons", 
        "graphics/temporal",
        "graphics/detailed",
        "data/processed",
        "data/raw"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"üìÅ Diret√≥rio verificado: {directory}")

def main():
    """Fun√ß√£o principal com menu interativo para gera√ß√£o de an√°lises LULC"""
    print("üõ∞Ô∏è AN√ÅLISE COMPLETA DAS INICIATIVAS LULC")
    print("=" * 60)
    print("üìä Sistema de An√°lise de Dados de Mapeamento LULC")
    print("üåç Compara√ß√£o entre iniciativas de monitoramento")
    print("üìÖ An√°lises temporais e comparativas detalhadas")
    print("=" * 60)
    
    if not check_dependencies():
        return False
    
    print("\nüìÅ CRIANDO DIRET√ìRIOS DE SA√çDA...")
    create_output_directories()
    
    while True:
        print("\nMENU PRINCIPAL:")
        print("1. Gerar An√°lises Comparativas")
        print("2. Gerar An√°lises Temporais")
        print("3. Gerar Apenas Dados Processados")
        print("0. Sair")
        opcao = input("Escolha uma op√ß√£o: ").strip()

        if opcao == "1":
            menu_analises_comparativas()
        elif opcao == "2":
            menu_analises_temporais()
        elif opcao == "3":
            menu_gerar_dados_processados()
        elif opcao == "0":
            print("Saindo...")
            break
        else:
            print("Op√ß√£o inv√°lida. Tente novamente.")

def menu_analises_comparativas():
    """Menu para an√°lises comparativas"""
    # Import direct from modular chart files for better performance
    from scripts.plotting.charts.distribution_charts import (
        plot_resolution_accuracy,
        plot_classes_por_iniciativa,
        plot_distribuicao_classes,
        plot_distribuicao_metodologias
    )
    from scripts.plotting.charts.timeline_chart import plot_timeline
    from scripts.plotting.charts.coverage_charts import plot_annual_coverage_multiselect
    
    opcoes = [
        ("Resolu√ß√£o vs Acur√°cia", plot_resolution_accuracy),
        ("Timeline de Iniciativas", plot_timeline),
        ("Cobertura Anual (Sele√ß√£o M√∫ltipla)", plot_annual_coverage_multiselect),
        ("Classes por iniciativa", plot_classes_por_iniciativa),
        ("Distribui√ß√£o de classes", plot_distribuicao_classes),
        ("Distribui√ß√£o de metodologias", plot_distribuicao_metodologias),
    ]
    
    print("\nAn√°lises Comparativas Dispon√≠veis:")
    for idx, (desc, _) in enumerate(opcoes, 1):
        print(f"{idx}. {desc}")
    print("0. Voltar ao menu principal")
    
    escolhas = input("Digite os n√∫meros das an√°lises desejadas separados por v√≠rgula (ex: 1,3,5): ").strip()
    if escolhas == "0":
        return
        
    indices = [int(i) for i in escolhas.split(",") if i.strip().isdigit() and 1 <= int(i) <= len(opcoes)]
      # Carregar dados uma vez
    from scripts.data_generation.data_wrapper import load_data, prepare_plot_data # Corrected import
    df, metadata, _ = load_data() # Corrected tuple unpacking
    df_prepared_dict = prepare_plot_data(df) # df_prepared is now a dict
    df_for_plots = df_prepared_dict.get('data', pd.DataFrame()) # Get the DataFrame from the dict
    
    for idx in indices:
        desc, func = opcoes[idx-1]
        print(f"\nüîÑ Gerando: {desc}")
        try:
            if desc == "Timeline de Iniciativas":
                func(metadata, df_for_plots)
            elif desc == "Cobertura Anual (Sele√ß√£o M√∫ltipla)":
                # Requires interactive selection, skipping for non-interactive run
                print(f"‚ö†Ô∏è {desc} requer sele√ß√£o interativa, pulando na execu√ß√£o de script.")
                # func(metadata, df_for_plots, df_for_plots['Name'].unique().tolist()[:3]) # Example if we wanted to force it
            elif desc == "Distribui√ß√£o de metodologias":
                method_counts = df_for_plots['Methodology'].value_counts() if 'Methodology' in df_for_plots and not df_for_plots.empty else pd.Series()
                func(method_counts)
            else:
                func(df_for_plots)
            print(f"‚úÖ {desc} gerado com sucesso!")
        except Exception as e:
            print(f"‚ùå Erro ao gerar {desc}: {e}")

def menu_analises_temporais():
    """Menu para an√°lises temporais"""
    print("\nüîÑ Executando an√°lises temporais...")
    try:
        run_analysis_step("analise_temporal", "An√°lises temporais das iniciativas")
    except Exception as e:
        print(f"‚ùå Erro nas an√°lises temporais: {e}")

def menu_gerar_dados_processados():
    """Menu para gerar apenas dados processados"""
    print("\nüîÑ Executando gera√ß√£o de dados processados...")
    print("üí° Esta op√ß√£o gera apenas os dados necess√°rios para o dashboard")
    print("üöÄ Processo otimizado - sem gr√°ficos")
    
    try:
        from scripts.data_generation.lulc_data_engine import UnifiedDataProcessor
        import json

        processor = UnifiedDataProcessor()

        # Gerar dataset principal
        print("\n1Ô∏è‚É£ GERANDO DATASET PRINCIPAL...")
        df, metadata = processor.load_data_from_jsonc()
        # Apply any additional processing if needed, similar to add_derived_metrics
        # For now, we assume load_data_from_jsonc and create_comprehensive_auxiliary_data cover it.
        
        # Adicionar coluna Sigla (Acronym) - This should ideally be part of the main data processing
        # If 'Acronym' is already generated by lulc_data_engine.py, this step might be redundant
        # or needs to be harmonized.
        # For now, let's assume 'Acronym' is handled or can be mapped here if necessary.
        # Example: if 'Acronym' is not in df.columns:
        # df['Acronym'] = df['Name'].map(processor.get_acronym_map()).fillna(df['Name'].str[:8])

        # Salvar dataset
        df.to_csv('data/processed/initiatives_processed.csv', index=False, encoding='utf-8')
        print(f"‚úÖ Dataset salvo: {len(df)} iniciativas")
        
        # Gerar metadados processados
        print("\n2Ô∏è‚É£ GERANDO METADADOS PROCESSADOS...")
        # metadata is already loaded, just need to save it
        output_path_metadata = 'data/processed/metadata_processed.json'
        with open(output_path_metadata, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Metadados salvos: {len(metadata)} iniciativas")

        # Gerar dados auxiliares
        print("\n3Ô∏è‚É£ GERANDO DADOS AUXILIARES PROCESSADOS...")
        auxiliary_data = processor.create_comprehensive_auxiliary_data(df, metadata)
        # Use the save_data method from the processor instance
        processor.save_data(auxiliary_data, 'data/processed/auxiliary_data.json', data_type="JSON")
        # output_path_auxiliary = 'data/processed/auxiliary_data.json'
        # with open(output_path_auxiliary, 'w', encoding='utf-8') as f:
        #     json.dump(auxiliary_data, f, ensure_ascii=False, indent=2)
        # print(f"‚úÖ Dados auxiliares salvos.") # Corrected f-string
        
        print("\nüéâ DADOS PROCESSADOS GERADOS COM SUCESSO!")
        print("üí° Os arquivos est√£o prontos para uso no dashboard")
        print("üìÅ Localiza√ß√£o: data/processed/")
        
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o de dados: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö° An√°lise interrompida pelo usu√°rio")
    except Exception as e:
        print(f"\n\n‚ùå ERRO CR√çTICO: {e}")
        print("üí° Verifique a instala√ß√£o e os arquivos de dados")
